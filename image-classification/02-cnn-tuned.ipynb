{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64489a5-4287-4276-8bf2-ca97a562441f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Convolutional Neural Networks Tuning\n",
    "\n",
    "In our [previous attempt](./01-cnn.ipynb) at image classification, we built a pretty decent convolutional neural network and achieved a respectable 74% accuracy on the CIFAR-10 dataset. However, we also observed a clear sign of overfitting - while training accuracy climbed, validation accuracy began to plateau and even dip.\n",
    "\n",
    "In this notebook, we will try to mitigate this issue by using multiple normalization techniques that are going to (hopefully) improve the model's accuracy and make it much more robust.\n",
    "\n",
    "<!--\n",
    "Articles used:\n",
    "- https://medium.com/@siddheshb008/vgg-net-architecture-explained-71179310050f\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806cfd9-0c9c-40c8-bcf8-61439a51ff46",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d810b4d-968e-4ca5-aa75-fc30db02dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "train, test = load_dataset('uoft-cs/cifar10', split=['train', 'test'])\n",
    "class_names = train.features['label'].names\n",
    "\n",
    "x_train = train['img']\n",
    "y_train = train['label']\n",
    "x_test = test['img']\n",
    "y_test = test['label']\n",
    "\n",
    "x_train = np.array([np.array(x) for x in x_train]).astype('float32') / 255.0\n",
    "x_test = np.array([np.array(x) for x in x_test]).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760eebe6-cd50-4960-a470-6a780aef8463",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Then, we may apply a technique called **data augumentation**. That's one of the most effective ways to combat overfitting and improve model generalization, especially with image data. \n",
    "\n",
    "This technique involves applying random (but realistic) transformations to our existing training images, effectively creating new training samples on the fly. This helps the model learn to be invariant to these slight variations - instead of simply memoizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7121aaf-8e6f-4642-afba-f170d52b1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Sequential\n",
    "data_augmentation = Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.15),\n",
    "    layers.RandomCrop(32, 32),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b805f6-d2f6-42f2-ae30-5a12e4064902",
   "metadata": {},
   "source": [
    "Let's visualize what these augmentations look like on a few sample images from our training set. You may clearly see that each image is slightly different from its original, yet still clearly recognizable. Note that we clip values to `[0, 1]` for proper display after augmentation, as some transformations might push pixel values slightly out of this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9a869b-c075-4694-b8a1-b23a3aba267a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: clip() received an invalid combination of arguments - got (int, int, out=NoneType), but expected one of:\n * (Tensor min = None, Tensor max = None)\n * (Number min = None, Number max = None)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m   plt.yticks([])\n\u001b[32m     10\u001b[39m   plt.grid(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m   plt.imshow(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_example\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     12\u001b[39m   plt.xlabel(class_names[y_train[i]])\n\u001b[32m     14\u001b[39m plt.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2169\u001b[39m, in \u001b[36mclip\u001b[39m\u001b[34m(a, a_min, a_max, out, **kwargs)\u001b[39m\n\u001b[32m   2100\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_clip_dispatcher)\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclip\u001b[39m(a, a_min, a_max, out=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   2102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2103\u001b[39m \u001b[33;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[32m   2104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2167\u001b[39m \n\u001b[32m   2168\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclip\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/numpy/core/fromnumeric.py:68\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(*args, **kwds)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/numpy/core/fromnumeric.py:45\u001b[39m, in \u001b[36m_wrapit\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m     44\u001b[39m     wrap = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m result = \u001b[38;5;28mgetattr\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, method)(*args, **kwds)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu.ndarray):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/_tensor.py:1192\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAACYCAYAAAD3AEsfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAktJREFUeJzt1rFq41AQQNGxSSunN9H/f1hAH2D11lZJs5gYNpcl4Zz2PcQUF705HcdxDITO/3sAfj+RkRMZOZGRExk5kZETGbmXZy7d7/fZtm2WZZnT6VTPxA9xHMfs+z7X63XO58f/q6ci27Zt1nX9tuH4Xd7f3+ft7e3h+VORLcvy+bHL5fI9k/Hj3W63Wdf1s49Hnors44m8XC4i4y9frVAWf3IiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyci/PXDqOY2ZmbrdbOgw/y0cPH3088lRk+77PzMy6rv84Fr/Rvu/z+vr68Px0fJXhzNzv99m2bZZlmdPp9K0D8nMdxzH7vs/1ep3z+fHm9VRk8C8s/uRERk5k5ERGTmTkREZOZOT+AKxgQ7j3OgPbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "augmented_example = data_augmentation(x_train[:25])\n",
    "plt.figure(figsize=[10, 10])\n",
    "\n",
    "for i in range(len(augmented_example)):\n",
    "  plt.subplot(5, 5, i + 1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(np.clip(augmented_example[i], 0, 1))\n",
    "  plt.xlabel(class_names[y_train[i]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7135b0-c4cb-4948-ba38-123f65deff28",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42f8790-77ad-4447-8a5d-57cb7e1db823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_encoded = to_categorical(y_train, num_classes=len(class_names))\n",
    "y_test_encoded = to_categorical(y_test, num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aee4ec-84df-41cd-ac68-396b4fce09f0",
   "metadata": {},
   "source": [
    "## Building and Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af81ff-1362-410f-8ff5-358f512b0760",
   "metadata": {},
   "source": [
    "For our improved model, we'll adopt a more robust, [VGG-inspired architecture](https://en.wikipedia.org/wiki/VGGNet), incorporating multiple normalization layers to stabilize training and deeper convolutional blocks to learn more intricate features.\n",
    "\n",
    "Its core idea is to use repeating blocks of convolutional layers. Each block will consist of:\n",
    "\n",
    "-   **Convolutional Layers:** We use two convolutional layers back-to-back. The first one finds initial features (like edges), and the second one looks at those features to find slightly more complex patterns (like corners or textures made of those edges) before we simplify things. It's like taking a first look, then a closer second look.\n",
    "-   **Batch Normalization:** After our convolutional layers work their magic, it steps in. It helps keep the learning process smooth and steady, like a good guide keeping everyone on track. This helps the network train faster and can also prevent it from getting too stuck on the training data (overfitting).\n",
    "-   **Activation Function:** Just like before, the `ReLU` activation helps the network make non-linear decisions, deciding which features are important enough to pass on. Note that is is put after the batch normalization, which is a pretty common practice.\n",
    "-   **Feature Condenser:** After finding detailed features, it picks out the strongest signals and shrinks the information. This makes our model more efficient and helps it recognize objects even if they are slightly moved or rotated.\n",
    "-   **Dropout:** To stop our network from simply memorizing the training images (which would make it bad at recognizing new images), it randomly ignores some of the learned features during training. This forces the network to be more robust and general ways to identify objects.\n",
    "\n",
    "By stacking these blocks, and progressively increasing the number of filters, we could build a neural network able to to perform complex visual understanding. The initial blocks might learn simple edges and colors, while deeper blocks combine these to recognize textures, parts of objects, and eventually, the objects themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c4d84c5-0707-465e-8941-5e2fdffee696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Sequential\n",
    "\n",
    "def vgg_block(filters, dropout_rate=0.15):\n",
    "    return Sequential([\n",
    "        layers.Conv2D(filters, (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Conv2D(filters, (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(dropout_rate),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468a35b-58ac-4da5-b3f5-a7be63973ccf",
   "metadata": {},
   "source": [
    "Just as before, our model will consist of two sub-models:\n",
    "\n",
    "- **Feature Learning**: Consists of multiple VGG blocks with gradual dropout, preceded by a data augmentation layer. This combination of regularization techniques makes our model less prone to overfitting.\n",
    "- **Classification:** Essentially, it remains the same, but we may add more neurons and some batch normalization here to make it more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "781af8ca-4750-47f9-aebd-f3c513a10c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ feature_learning (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ random_flip_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ random_rotation_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomRotation</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ random_zoom_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomZoom</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ random_crop_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomCrop</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_9   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_9            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_10  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_10           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ max_pooling2d_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_11  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_11           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_12  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_12           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ max_pooling2d_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">222,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_13  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_13           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_14  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_14           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ max_pooling2d_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">887,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_15  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_15           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_16  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_16           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ max_pooling2d_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classification (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,386</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ global_average_pooling2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ batch_normalization_17     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ activation_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ feature_learning (\u001b[38;5;33mSequential\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,176,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_6 (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ random_flip_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomFlip\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ random_rotation_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomRotation\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ random_zoom_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomZoom\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ random_crop_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomCrop\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_7 (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m10,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_9   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_9            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_10  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_10           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ max_pooling2d_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_8 (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m55,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_11  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_11           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_12  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_12           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ max_pooling2d_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_9 (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m222,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_13  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_13           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_14  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_14           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ max_pooling2d_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ sequential_10 (\u001b[38;5;33mSequential\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m887,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_15  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_15           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ batch_normalization_16  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ activation_16           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ max_pooling2d_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│       └ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classification (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m69,386\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ global_average_pooling2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ batch_normalization_17     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ activation_17 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,245,482</span> (4.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,245,482\u001b[0m (4.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,243,050</span> (4.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,243,050\u001b[0m (4.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,432\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "feature_learning = Sequential(name='feature_learning', layers=[\n",
    "    layers.Input(shape=x_train.shape[1:]),\n",
    "    data_augmentation,\n",
    "    vgg_block(32,  dropout_rate=0.15),\n",
    "    vgg_block(64,  dropout_rate=0.25),\n",
    "    vgg_block(128, dropout_rate=0.35),\n",
    "    vgg_block(256, dropout_rate=0.45),\n",
    "])\n",
    "\n",
    "classification = Sequential(name = 'classification', layers=[\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.35),\n",
    "    layers.Dense(len(class_names), activation='softmax'),\n",
    "])\n",
    "\n",
    "model = Sequential([\n",
    "    feature_learning,\n",
    "    classification,\n",
    "])\n",
    "\n",
    "display(model.summary(expand_nested=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75d30f-a237-45d3-aef0-5bc9bfbbacf4",
   "metadata": {},
   "source": [
    "To aid our training process, we could use a combination of **learning rate scheduling** and **early stopping** callbacks. The last one will stop the training process if the validation loss doesn't improve for a set number of epochs, also restoring the best possible weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9de53279-bf7b-4b99-865c-7f78aa1019f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=10, min_lr=0.00001)\n",
    "callbacks = [reduce_lr, earlystop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235576e-6502-4382-85b2-8de1b01aeafa",
   "metadata": {},
   "source": [
    "We'll might also use the `AdamW` optimizer, which is an extension of the Adam optimizer that incorporates the normalization technique called **weight decay**, often leading to better generalization.\n",
    "\n",
    "That's a regularization technique that helps prevent overfitting by adding a penalty to the loss function proportional to the model's weights. By keeping them smaller, the model tends to be simpler and less likely to fit the noise in the training data, leading to better generalization on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9c9e514-b039-4e1c-9310-9ec5bb4991cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import AdamW\n",
    "optimizer = AdamW(weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750bb93-943c-443f-9367-02707f28a3a7",
   "metadata": {},
   "source": [
    "Now, let's compile and train our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61b41366-2be4-411a-9813-5f2c105813b2",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model.compile(optimizer=optimizer, loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/_tensor.py:624\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    616\u001b[39m         Tensor.backward,\n\u001b[32m    617\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    622\u001b[39m         inputs=inputs,\n\u001b[32m    623\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable._execution_engine.run_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m         t_outputs, *args, **kwargs\n\u001b[32m    827\u001b[39m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train_encoded, epochs=100, batch_size=64, callbacks=callbacks, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bad6f6-05d7-4c37-861b-be6fef49e04b",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ab40c9-f87e-468f-bb11-7450f917888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.88      0.90      0.89      1000\n",
      "  automobile       0.92      0.95      0.93      1000\n",
      "        bird       0.88      0.81      0.85      1000\n",
      "         cat       0.84      0.69      0.76      1000\n",
      "        deer       0.88      0.86      0.87      1000\n",
      "         dog       0.85      0.81      0.83      1000\n",
      "        frog       0.82      0.96      0.88      1000\n",
      "       horse       0.89      0.93      0.91      1000\n",
      "        ship       0.94      0.91      0.93      1000\n",
      "       truck       0.86      0.94      0.90      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.87     10000\n",
      "weighted avg       0.88      0.88      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "with device('/GPU'):\n",
    "    y_pred_probs = model.predict(x_test, verbose=False)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true_labels = np.argmax(y_test_encoded, axis=1)\n",
    "    print(classification_report(y_true_labels, y_pred_labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff904073-3d14-47b7-abc8-edbaf41e91b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4.5, 3))\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4fe946-baa3-4a38-83e2-41798be74e08",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By systematically incorporating data augmentation, architectural changes, and training callbacks, we have substantially boosted our model's performance. The leap to a much more compelling **88%** accuracy on the CIFAR-10 test set clearly demonstrates the power of these combined techniques.\n",
    "\n",
    "More importantly, these improvements weren't just about chasing a higher accuracy figure - they were crucial in addressing the overfitting observed previously. The model now generalizes better to unseen data, making it much more reliable. \n",
    "\n",
    "While this tuned model shows significant progress, future improvements could involve experimenting with even deeper or wider networks, attention mechanisms, or leveraging transfer learning for even greater accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
