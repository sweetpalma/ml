{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1328c26f-f4c4-459e-b0e1-51208b368377",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "In our [previous MLP experiment](./03-mlp.ipynb), we saw that a neural network could extract more from averaged word embeddings than a simple Logistic Regression. However, averaging throws away crucial information - the order of words in a sentence.\n",
    "\n",
    "This time, we are going to dive deeper into **recurrent neural networks**. They are specifically designed to process sequences, remembering context and understanding how word order contributes to meaning. Let's see if harnessing this sequential power can push our accuracy even further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7778f81-c1de-4370-8059-7746a7f51ff3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf07db0-756f-4ff1-bc78-e47f125eb564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset('stanfordnlp/imdb', split='train+test')\n",
    "train, test = ds.train_test_split(test_size=0.2, seed=0).values()\n",
    "class_names = ds.features['label'].names\n",
    "\n",
    "x_train = train['text']\n",
    "y_train = train['label']\n",
    "x_test = test['text']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554972f5-640d-45a8-b5b6-f12d663ea3b9",
   "metadata": {},
   "source": [
    "## Data Encoding\n",
    "\n",
    "In our previous notebook, we simply tokenized text and then immediately squashed it into the averaged word vectors. Our new recurrent pipeline needs to be a bit more complicated.\n",
    "\n",
    "This time, we would simply **tokenize** our sentences first - without trying to vectorize them. We might limit the vocabulary, making it more robust and accurate representation of frequently occurring words by filtering out rare or noisy terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718fb948-3b18-4c9f-acf1-fd0cb0c31c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5100, 182]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "\n",
    "max_vocab = 45000\n",
    "tokenizer = Tokenizer(num_words=max_vocab, oov_token='<oov>')\n",
    "\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "display(tokenizer.texts_to_sequences(['Hello World']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b724b6-e573-483b-ac63-ba0adc323d24",
   "metadata": {},
   "source": [
    "Next, we need to **pad** our sequences. Most neural networks require input sequences to be of a uniform length. Since our sentences naturally vary, we need to bring them to the same length. \n",
    "\n",
    "This involves either truncating longer sequences or adding special tokens (usually zeros) to shorter sequences until they all reach a predetermined maximum length. Let's do a small research to determine how long our sequences usually are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e645d0-2af6-4edc-bac6-f41484920ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40000.000000\n",
       "mean       231.142550\n",
       "std        171.694078\n",
       "min          4.000000\n",
       "25%        126.000000\n",
       "50%        173.000000\n",
       "75%        280.000000\n",
       "95%        591.000000\n",
       "99%        908.000000\n",
       "max       2470.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_lengths = train.to_pandas()['text'].apply(lambda x: len(x.split()))\n",
    "display(text_lengths.describe(percentiles=[0.25, 0.5, 0.75, 0.95, 0.99]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1319ad8-3e32-48e9-9a34-785271308c9b",
   "metadata": {},
   "source": [
    "Taking the top quartile length seems to be a reasonable choice here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a705e757-43a8-475b-bdd6-8636769f3f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   15,     4, 17144, ...,     7,    71,  1154],\n",
       "       [    0,     0,     0, ...,     4,   702,   156],\n",
       "       [    0,     0,     0, ...,     5,  1951,   447],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     4,  3022,  2878],\n",
       "       [    0,     0,     0, ...,   405,    81,   120],\n",
       "       [    0,     0,     0, ...,     8,   340,   156]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40000, 280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "max_seq = 280\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(x_train), maxlen=max_seq)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(x_test), maxlen=max_seq)\n",
    "\n",
    "display(x_train)\n",
    "display(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f1e4da-04dd-493c-bb4d-1b89ee6dc07d",
   "metadata": {},
   "source": [
    "## Embedding Layer\n",
    "\n",
    "Finally, we need to transform these padded sequences into some meaningful representation that captures their semantic relationships. That's where the **embedding layer** comes in. To build it, we may utilize our existing pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87ef7df-f983-4f68-8fd4-ecbe96312d5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba595dd2e7b04e1ca8550c48c6dc60f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os import path\n",
    "from huggingface_hub import snapshot_download\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_path = path.join(snapshot_download('fse/word2vec-google-news-300'), 'word2vec-google-news-300.model')\n",
    "wv = KeyedVectors.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883aa41-cc3c-4850-a70e-2630fde63690",
   "metadata": {},
   "source": [
    "Think of it as a sophisticated, trainable lookup table - for each token in our sequence, the embedding layer looks up its corresponding dense vector. This helps our neural network to capture not some random indexes, but the *semantic* meaning of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1612d0e-fc73-4675-8534-de9f591129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embedding_matrix_shape = (max_vocab, wv.vector_size)\n",
    "embedding_matrix = np.zeros(shape=embedding_matrix_shape)\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index < max_vocab:\n",
    "        if word in wv:\n",
    "            embedding_matrix[index] = wv.get_vector(word)\n",
    "        else:\n",
    "            embedding_matrix[index] = np.zeros(wv.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e638abb1-d4a5-4366-9731-1389be7692a3",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c2f809-7c53-45b3-ae16-cc60ec1f12eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_encoded = to_categorical(y_train, num_classes=len(class_names))\n",
    "y_test_encoded = to_categorical(y_test, num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a1dbbc-fa62-4355-af58-fe4f63a030f1",
   "metadata": {},
   "source": [
    "## Building and Training the Model\n",
    "\n",
    "Here comes the most interesting part. With our text now represented as sequences of dense semantic vectors (thanks to the embedding layer), we can introduce the star of this experiment - the **Long Short-Term Memory (LSTM)** layer.\n",
    "\n",
    "Unlike a simple dense layer that processes all its inputs at once, an LSTM processes each vector in our sequence one at a time. Internally, each LSTM unit contains a sophisticated set of **gates** – an input gate, a forget gate, and an output gate – along with a memory cell.\n",
    "\n",
    "These gates learn to control the flow of information, deciding what to remember from previous steps, what to discard, and what new information from the current word's vector is important enough to update its memory, allowing it to capture *context* and *dependencies* across the entire sequence.\n",
    "\n",
    "We may also make the recurrent layer **bidirectional**, wrapping it in a special helper function - this will allow the network to capture information from both past and future time steps, leading to a more comprehensive understanding of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8333ee3c-872d-4ac2-9ef6-3f0c56a40826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">280</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,500,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">280</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">280</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,140,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m280\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │    \u001b[38;5;34m13,500,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m280\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m280\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,140,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,026\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,641,762</span> (55.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,641,762\u001b[0m (55.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,641,762</span> (55.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,641,762\u001b[0m (55.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import set_random_seed\n",
    "from keras import layers, Sequential\n",
    "set_random_seed(0)\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(max_seq,)),\n",
    "    layers.Embedding(\n",
    "        weights=[embedding_matrix],\n",
    "        input_dim=embedding_matrix_shape[0],\n",
    "        output_dim=embedding_matrix_shape[1],\n",
    "        trainable=True,\n",
    "    ),\n",
    "    layers.SpatialDropout1D(0.35),\n",
    "    layers.Bidirectional(layers.LSTM(256, return_sequences=True)),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(len(class_names), activation='softmax'),\n",
    "])\n",
    "\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d300effc-a4e5-4963-81ca-dd11e611310e",
   "metadata": {},
   "source": [
    "Before we start the training, we might tweak a few more things. Changing the optimizer learning rate may be a good idea - the default one might be too high when fine-tuning pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be945fe-c351-4a71-899e-20bd0ed86905",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import AdamW\n",
    "optimizer = AdamW(learning_rate=0.0001, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b191b-5984-416f-8409-cb993f800703",
   "metadata": {},
   "source": [
    "Also, we might introduce a **learning rate scheduler** called `ReduceLROnPlateau` - it automatically reduces the optimizer's learning rate when a monitored metric (like validation loss) stops improving for a specified number of epochs (patience limit). This helps the model escape local minima and fine-tune its weights more precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8647282-d4c3-4ee2-ab69-479e35677ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab0c0f-dc5a-41f0-ba5f-d6200cbd8144",
   "metadata": {},
   "source": [
    "Now, let's compile and train our final model. This time we might start using the GPU - our model is finally complex enough to leverage the parallelism it offers to speed up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844a91a-c0f1-454b-961d-ec0d16eaf829",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m145/500\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:00\u001b[0m 678ms/step - accuracy: 0.5416 - loss: 0.6928"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train_encoded, epochs=20, batch_size=64, callbacks=[reduce_lr], validation_split=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4ab5f-7b61-4d05-9326-a6c22ae5083a",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff80d1-d975-4934-877f-610e21440a8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "y_pred_probs = model.predict(x_test, verbose=False)\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_labels = np.argmax(y_test_encoded, axis=1)\n",
    "print(classification_report(y_true_labels, y_pred_labels, target_names=ds.features['label'].names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f887c-af46-4e72-ae68-fc85b53b14ac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4.5, 3))\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda7276-fb61-44a1-a38b-cbf544ba5f1a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We achieved a final accuracy of **91%**, ultimately outperforming the linear model. It became possible by combining LSTM units with pre-trained word embeddings, enabling the model to leverage sequential information.\n",
    "\n",
    "This proves the value of sequence-aware models over simple embedding averaging for this type of task, performing competitively with the heavily optimized count vectorizer approach. Further improvements would likely require exploring more advanced architectures like transformers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
